{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this competition, you will forecast the demand of a product for a given week, at a particular store. The dataset you are given consists of 9 weeks of sales transactions in Mexico. Every week, there are delivery trucks that deliver products to the vendors. Each transaction consists of sales and returns. Returns are the products that are unsold and expired. The demand for a product in a certain week is defined as the sales this week subtracted by the return next week.\n",
    "\n",
    "The train and test dataset are split based on time, as well as the public and private leaderboard dataset split.\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- There may be products in the test set that don't exist in the train set. This is the expected behavior of inventory data, since there are new products being sold all the time. Your model should be able to accommodate this.\n",
    "- There are duplicate Cliente_ID's in cliente_tabla, which means one Cliente_ID may have multiple NombreCliente that are very similar. This is due to the NombreCliente being noisy and not standardized in the raw data, so it is up to you to decide how to clean up and use this information. \n",
    "- The adjusted demand (Demanda_uni_equil) is always >= 0 since demand should be either 0 or a positive value. The reason that Venta_uni_hoy - Dev_uni_proxima sometimes has negative values is that the returns records sometimes carry over a few weeks.\n",
    "<br><br>\n",
    "- ```Semana``` — Week number (From Thursday to Wednesday)\n",
    "- ```Agencia_ID``` — Sales Depot ID\n",
    "- ```Canal_ID``` — Sales Channel ID\n",
    "- ```Ruta_SAK``` — Route ID (Several routes = Sales Depot)\n",
    "- ```Cliente_ID``` — Client ID\n",
    "- ```NombreCliente``` — Client name\n",
    "- ```Producto_ID``` — Product ID\n",
    "- ```NombreProducto``` — Product Name\n",
    "- ```Venta_uni_hoy``` — Sales unit this week (integer)\n",
    "- ```Venta_hoy``` — Sales this week (unit: pesos)\n",
    "- ```Dev_uni_proxima``` — Returns unit next week (integer)\n",
    "- ```Dev_proxima``` — Returns next week (unit: pesos)\n",
    "- ```Demanda_uni_equil``` — Adjusted Demand (integer) (This is the target you will predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping error calc\n",
    "def rmsle_loop(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando somente as 3 primeiras semanas\n",
    "\n",
    "#df = pd.read_csv('train.csv')\n",
    "#df[df.Semana.isin([3, 4, 5])].to_csv('train_345.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Qubrando novamente em datasets separados\n",
    "\n",
    "#df = pd.read_csv('train_345.csv')\n",
    "#df[df.Semana.isin([3])].to_csv('train_3.csv')\n",
    "#df[df.Semana.isin([4])].to_csv('train_4.csv')\n",
    "#df[df.Semana.isin([5])].to_csv('train_5.csv')\n",
    "\n",
    "#df[df.Semana.isin([8,9])].to_csv('train_8_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {#'Semana':'uint8',\n",
    "         #'Canal_ID':'uint8',\n",
    "         #'Agencia_ID':'uint16',\n",
    "         #'Ruta_SAK':'uint16',\n",
    "         'Dev_uni_proxima':'uint16',\n",
    "         'Cliente_ID':'uint32',\n",
    "         'Producto_ID':'uint32',\n",
    "         'Venta_uni_hoy':'uint8',\n",
    "         'Demanda_uni_equil':'uint32',\n",
    "         'Venta_hoy':'float32',\n",
    "         'Dev_proxima':'float32'}\n",
    "\n",
    "usecols=[#'Semana', \n",
    "         #'Canal_ID',\n",
    "         #'Agencia_ID', \n",
    "         #'Ruta_SAK', \n",
    "         'Cliente_ID', \n",
    "         'Producto_ID', \n",
    "         'Venta_uni_hoy', \n",
    "         'Venta_hoy',\n",
    "         'Dev_uni_proxima', \n",
    "         'Dev_proxima', \n",
    "         'Demanda_uni_equil']\n",
    "\n",
    "df = pd.read_csv('train_345.csv', dtype=dtype, usecols=usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(df.iloc[:, :-1])\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:32:56] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='reg:linear', random_state=42,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log1p\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11037768329008704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo validação com semanas 8 e 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('train_8_9.csv', dtype=dtype, usecols=usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = StandardScaler().fit_transform(df_val)\n",
    "X_ = df_val[:,:-1]\n",
    "y_ = df_val[:,-1]\n",
    "\n",
    "del df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_val = xgb_clf.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_val[result_val < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle(y_, result_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([y_, result_val]).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
